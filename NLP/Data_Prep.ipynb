{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9435"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json\n",
    "import json\n",
    "df = json.load(open('NER_TRAIN_JUDGEMENT.json'))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'annotations', 'data', 'meta'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' \\n5.2 CW3 Mr Vijay Mishra , Deputy Manager, HDFC Bank, Noida, UP has deposed that complainant had a current account with HDFC Bank in the year 2004\\xad2005.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': {'start': 90, 'end': 103, 'text': 'Hongkong Bank', 'labels': ['ORG']}, 'id': 'C8HPTIM1', 'from_name': 'label', 'to_name': 'text', 'type': 'labels'}\n",
      "{'value': {'start': 267, 'end': 278, 'text': 'Rahul & Co.', 'labels': ['ORG']}, 'id': 'KOWE3RAM', 'from_name': 'label', 'to_name': 'text', 'type': 'labels'}\n"
     ]
    }
   ],
   "source": [
    "for i in df[0]['annotations'][0]['result']:\n",
    "   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hongkong Bank'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = df[0]['annotations'][0]['result'][0]['value']['start']\n",
    "end = df[0]['annotations'][0]['result'][0]['value']['end']\n",
    "df[0]['data'][\"text\"][start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[0]['data'][\"text\"]\n",
    "for i in df[0]['annotations'][-1]['result']:\n",
    "    # replace the text with the entity\n",
    "    start = i['value']['start']\n",
    "    end = i['value']['end']\n",
    "    label = i['value']['labels'][0]\n",
    "    text = i['value']['text'].split()\n",
    "    new_text = \"B\"+\"_\"+label+ (\" \" +\"I\"+\"_\"+label)*(len(text)-1)\n",
    "    # replace the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rahul', '&', 'Co.']\n"
     ]
    }
   ],
   "source": [
    "print(text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n(7)', 'On', 'specific', 'query', 'by', 'the', 'Bench', 'about', 'an', 'entry', 'of', 'Rs.', '1,31,37,500', 'on', 'deposit', 'side', 'of', 'Hongkong', 'Bank', 'account', 'of', 'which', 'a', 'photo', 'copy', 'is', 'appearing', 'at', 'p.', '40', 'of', \"assessee's\", 'paper', 'book,', 'learned', 'authorised', 'representative', 'submitted', 'that', 'it', 'was', 'related', 'to', 'loan', 'from', 'broker,', 'Rahul', '&', 'Co.', 'on', 'the', 'basis', 'of', 'his', 'submission', 'a', 'necessary', 'mark', 'is', 'put', 'by', 'us', 'on', 'that', 'photo', 'copy.']\n"
     ]
    }
   ],
   "source": [
    "text = df[0]['data'][\"text\"]\n",
    "tokens = text.split(\" \")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIO_Encoder(text,annotations):\n",
    "    # text = df[0]['data'][\"text\"]\n",
    "    tokens = text.split(\" \")\n",
    "\n",
    "    start_idx = 0\n",
    "    token_positions = []\n",
    "    for token in tokens:\n",
    "        end_idx = start_idx + len(token)\n",
    "        token_positions.append((start_idx, end_idx))\n",
    "        # print(text[start_idx:end_idx])\n",
    "        start_idx = end_idx + 1 # +1 accounts for the space\n",
    "        \n",
    "    bio_labels = [\"O\"] * len(tokens)\n",
    "    # annotations = df[0]['annotations'][0]['result']\n",
    "\n",
    "    for annotation in annotations:\n",
    "        span_start = annotation['value']['start']\n",
    "        span_end = annotation['value']['end']\n",
    "        label = annotation['value']['labels'][0]\n",
    "                \n",
    "        for idx, (token_start, token_end) in enumerate(token_positions):\n",
    "                if token_start >= span_start and token_end <= span_end:\n",
    "                    if token_start == span_start:\n",
    "                        bio_labels[idx] = f\"B_{label}\"\n",
    "                    else:\n",
    "                        bio_labels[idx] = f\"I_{label}\"\n",
    "    return bio_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(token_positions)\n",
    "# print(bio_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8019, 1416)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data (randomly stratified) into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.15, random_state=42)\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = {}\n",
    "new_df_test = {}\n",
    "\n",
    "for i in df_train:\n",
    "    id = i['id']\n",
    "    text = i['data'][\"text\"]\n",
    "    annotations = i['annotations'][-1]['result']\n",
    "\n",
    "    new_df_train[id] = {\"text\":text, \"labels\":  BIO_Encoder(text,annotations)}\n",
    "\n",
    "for i in df_test:\n",
    "    id = i['id']\n",
    "    text = i['data'][\"text\"]\n",
    "    annotations = i['annotations'][-1]['result']\n",
    "\n",
    "    new_df_test[id] = {\"text\":text, \"labels\":  BIO_Encoder(text,annotations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the json files\n",
    "with open('train.json', 'w') as f:\n",
    "    json.dump(new_df_train, f)\n",
    "\n",
    "with open('test.json', 'w') as f:\n",
    "    json.dump(new_df_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore, while interpreting statutory provisions, the courts should keep in mind the objectives or purpose for which statute has been enacted.\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "The petitioner in W.P.No.15821 of 2008 was never considered for appointment under the National Rural Employment Guarantee Scheme either through Employment Exchange sponsorship or by Outsourcing Agencies.\n",
      "['O', 'O', 'O', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'I_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "The factum of accident, allegation of rash and negligent driving causing death of Sukendra Pal Singh were denied.\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_OTHER_PERSON', 'I_OTHER_PERSON', 'I_OTHER_PERSON', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "c = 2\n",
    "for i in new_df_train:\n",
    "    print(new_df_train[i]['text'])\n",
    "    print(new_df_train[i]['labels'])\n",
    "\n",
    "    if c == 0:\n",
    "        break\n",
    "    c -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W.P.No.15821 of 2008'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[1][\"data\"][\"text\"][18:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
